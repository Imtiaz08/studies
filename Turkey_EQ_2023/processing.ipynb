{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "848794ed",
   "metadata": {},
   "source": [
    "# Usage\n",
    "\n",
    "This notebook is distributes using MIT licence\n",
    "\n",
    "    MIT License\n",
    "\n",
    "    Copyright (c) [2023] [Artem Vesnin]\n",
    "\n",
    "    Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "    of this software and associated documentation files (the \"Software\"), to deal\n",
    "    in the Software without restriction, including without limitation the rights\n",
    "    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "    copies of the Software, and to permit persons to whom the Software is\n",
    "    furnished to do so, subject to the following conditions:\n",
    "\n",
    "    The above copyright notice and this permission notice shall be included in all\n",
    "    copies or substantial portions of the Software.\n",
    "\n",
    "    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "    SOFTWARE.\n",
    "\n",
    "# Site the paper[coming soon] if you use this code for research\n",
    "\n",
    "# Data availabilty \n",
    "\n",
    "Data of global GNSS network are available at https://simurg.space. Email artem_vesnin@iszf.irk.ru for addtional data that are not availble publically. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d47afd",
   "metadata": {},
   "source": [
    "# Prepare environment\n",
    "\n",
    "Load anaconda to make sure we on the same page.\n",
    "\n",
    "https://docs.conda.io/en/latest/\n",
    "\n",
    "In anaconda propmt (or in linux bash):\n",
    "\n",
    "```bash\n",
    "conda deactivate\n",
    "conda create -n turkey_eq python=3.10\n",
    "conda activate turkey_eq\n",
    "conda install jupyterlab\n",
    "conda install cartopy\n",
    "jupyter-notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8721be",
   "metadata": {},
   "source": [
    "# Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057564ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "!pip install h5py\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525cc335",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "We already collect data and provide urls below. You can do it by your own on SIMuRG site under [create_map](https://simurg.iszf.irk.ru/create_map) option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbd23fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "URLS = {\"roti_10_24.h5\": \n",
    "            \"https://simurg.space/files/roti_2023_037_25_50_N_25_50_E_645f.h5\",\n",
    "        \"dtec_2_10_10_24.h5\": \n",
    "            \"https://simurg.space/files/dtec_2_10_2023_037_25_50_N_25_50_E_1447.h5\",\n",
    "        \"dtec_10_20_10_24.h5\": \n",
    "            \"https://simurg.space/files/dtec_10_20_2023_037_25_50_N_25_50_E_840f.h5\",\n",
    "        \"dtec_20_60_10_24.h5\": \n",
    "            \"https://simurg.space/files/dtec_20_60_2023_037_25_50_N_25_50_E_6769.h5\",        \n",
    "        \"roti_01_17.h5\": \n",
    "            \"https://simurg.space/files/roti_2023_037_25_50_N_25_50_E_c5ab.h5\",\n",
    "        \"dtec_2_10_01_17.h5\": \n",
    "            \"https://simurg.space/files/dtec_2_10_2023_037_25_50_N_25_50_E_421a.h5\",\n",
    "        \"dtec_10_20_01_17.h5\": \n",
    "            \"https://simurg.space/files/dtec_10_20_2023_037_25_50_N_25_50_E_2051.h5\",\n",
    "        \"dtec_20_60_01_17.h5\": \n",
    "            \"https://simurg.space/files/dtec_20_60_2023_037_25_50_N_25_50_E_b483.h5\",\n",
    "       }\n",
    "\n",
    "URLS.update({ \"roti_10_24.h5\": \n",
    "                    \"https://simurg.space/ufiles/roti_2023_037_25_50_N_25_50_E_8fc2.h5\",\n",
    "              \"dtec_2_10_10_24.h5\": \n",
    "                    \"https://simurg.space/ufiles/dtec_2_10_2023_037_25_50_N_25_50_E_cfeb.h5\",\n",
    "              \"dtec_10_20_10_24.h5\": \n",
    "                    \"https://simurg.space/ufiles/dtec_10_20_2023_037_25_50_N_25_50_E_3290.h5\",\n",
    "              \"dtec_20_60_10_24.h5\": \n",
    "                    \"https://simurg.space/ufiles/dtec_20_60_2023_037_25_50_N_25_50_E_30d5.h5\",        \n",
    "              \"roti_01_17.h5\": \n",
    "                  \"https://simurg.space/ufiles/roti_2023_037_25_50_N_25_50_E_d6aa.h5\",\n",
    "              \"dtec_2_10_01_17.h5\": \n",
    "                  \"https://simurg.space/ufiles/dtec_2_10_2023_037_25_50_N_25_50_E_44e1.h5\",\n",
    "              \"dtec_10_20_01_17.h5\": \n",
    "                  \"https://simurg.space/ufiles/dtec_10_20_2023_037_25_50_N_25_50_E_d0de.h5\",\n",
    "              \"dtec_20_60_01_17.h5\": \n",
    "                  \"https://simurg.space/ufiles/dtec_20_60_2023_037_25_50_N_25_50_E_77bc.h5\"\n",
    "            }\n",
    "           )\n",
    "\n",
    "\n",
    "FILES_PRODUCT_10_24 = {\"roti_10_24.h5\": \"ROTI\",\n",
    "                       \"dtec_2_10_10_24.h5\": \"2-10 minute TEC variations\",\n",
    "                       \"dtec_10_20_10_24.h5\": \"10-20 minute TEC variations\",\n",
    "                       \"dtec_20_60_10_24.h5\": \"20-60 minute TEC variations\",\n",
    "                      }\n",
    "\n",
    "FILES_PRODUCT_01_17 = {\"roti_01_17.h5\": \"ROTI\",\n",
    "                       \"dtec_2_10_01_17.h5\": \"2-10 minute TEC variations\",\n",
    "                       \"dtec_10_20_01_17.h5\": \"10-20 minute TEC variations\",\n",
    "                       \"dtec_20_60_01_17.h5\": \"20-60 minute TEC variations\",\n",
    "                      }\n",
    "\n",
    "TNPGN_FILES_PRODUCT_10_24 = {\"tnpgn_roti_10_24.h5\": \"ROTI\",\n",
    "                             \"tnpgn_dtec_2_10_10_24.h5\": \"2-10 minute TEC variations\",\n",
    "                             \"tnpgn_dtec_10_20_10_24.h5\": \"10-20 minute TEC variations\",\n",
    "                             \"tnpgn_dtec_20_60_10_24.h5\": \"20-60 minute TEC variations\",\n",
    "                            }\n",
    "\n",
    "TNPGN_FILES_PRODUCT_01_17 = {\"tnpgn_roti_01_17.h5\": \"ROTI\",\n",
    "                             \"tnpgn_dtec_2_10_01_17.h5\": \"2-10 minute TEC variations\",\n",
    "                             \"tnpgn_dtec_10_20_01_17.h5\": \"10-20 minute TEC variations\",\n",
    "                             \"tnpgn_dtec_20_60_01_17.h5\": \"20-60 minute TEC variations\",\n",
    "                            }\n",
    "\n",
    "for local_file, url in URLS.items():\n",
    "    if not os.path.exists(local_file):\n",
    "        response = requests.get(url)\n",
    "        open(local_file, \"wb\").write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025ec12c",
   "metadata": {},
   "source": [
    "# Including necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862fcd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dt\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy import feature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from datetime import (datetime, \n",
    "                      timedelta)\n",
    "from dateutil import tz\n",
    "from collections import defaultdict\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc676607",
   "metadata": {},
   "source": [
    "# Define some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34417c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_LIMITS ={\n",
    "    'ROTI': [-0,0.5,'TECu/min'],\n",
    "    '2-10 minute TEC variations': [-0.2,0.2,'TECu'],\n",
    "    '10-20 minute TEC variations': [-0.4,0.4,'TECu'],\n",
    "    '20-60 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    'tec': [0,50,'TECu/min'],\n",
    "    'tec_adjusted': [0,50,'TECu'],\n",
    "}\n",
    "\n",
    "DEFAULT_PARAMS = {'font.size': 20,\n",
    "                  'figure.dpi': 300,\n",
    "                  'font.family': 'sans-serif',\n",
    "                  'font.style': 'normal',\n",
    "                  'font.weight': 'light',\n",
    "                  'legend.frameon': True,\n",
    "                  'font.variant' : 'small-caps',\n",
    "                  'axes.titlesize' : 20,\n",
    "                  'axes.labelsize' : 20,\n",
    "                  'xtick.labelsize' : 18,                         \n",
    "                  'xtick.major.pad': 5,\n",
    "                  'ytick.major.pad': 5,   \n",
    "                  'xtick.major.width' : 2.5,\n",
    "                  'ytick.major.width' : 2.5,\n",
    "                  'xtick.minor.width' : 2.5,\n",
    "                  'ytick.minor.width' : 2.5,\n",
    "                  'ytick.labelsize' : 20}\n",
    "\n",
    "TIME_FORMAT = '%Y-%m-%d %H:%M:%S.%f'\n",
    "\n",
    "EPICENTERS = {'01:17': {'lat': 37.220, \n",
    "                        'lon': 37.019, \n",
    "                        'time': datetime(2023, 2, 6, 1, 17, 34)},\n",
    "              '10:24': {'lat': 38.016, \n",
    "                        'lon': 37.206, \n",
    "                        'time': datetime(2023, 2, 6, 10, 24, 50)}\n",
    "             }\n",
    "\n",
    "_UTC = tz.gettz('UTC')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d44de6",
   "metadata": {},
   "source": [
    "# Rertrieve and plot methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef45c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_layout(ax, \n",
    "                   lon_limits,\n",
    "                   lat_limits):\n",
    "    plt.rcParams.update(DEFAULT_PARAMS)\n",
    "    gl = ax.gridlines(linewidth=2, color='gray', alpha=0.5, draw_labels=True, linestyle='--')\n",
    "    gl.xlabels_top = False\n",
    "    gl.ylabels_right = False\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    ax.set_xlim(*lon_limits)\n",
    "    ax.set_ylim(*lat_limits)\n",
    "    #put some features on the map\n",
    "    ax.add_feature(feature.COASTLINE, linewidth=2.5)\n",
    "    ax.add_feature(feature.BORDERS, linestyle=':', linewidth=2)\n",
    "    ax.add_feature(feature.LAKES, alpha=0.5)\n",
    "    ax.add_feature(feature.RIVERS)\n",
    "    \n",
    "#Plot data for one time moment\n",
    "def plot_map(plot_times, data, type_d,\n",
    "             lon_limits=(-180, 180), \n",
    "             lat_limits=(-90, 90),\n",
    "             nrows=1, \n",
    "             ncols=3,\n",
    "             markers=[], \n",
    "             sort=False,\n",
    "             use_alpha=False,\n",
    "             clims=C_LIMITS, \n",
    "             savefig=''):\n",
    "    \"\"\"\n",
    "    Plotting data\n",
    "    input - <time> string type time from SIMuRG map file \n",
    "            <lats> list of latitudes \n",
    "            <lons> list of longitudes \n",
    "            <values> list of values\n",
    "            <type_d> string type of data going to be plotted\n",
    "    output - figure\n",
    "    \"\"\"  \n",
    "    assert len(plot_times) == ncols\n",
    "    if isinstance(type_d, list):\n",
    "        assert len(type_d) == nrows\n",
    "    else:\n",
    "        type_d = [type_d]\n",
    "    fig, axs = plt.subplots(nrows=nrows,ncols=ncols,\n",
    "                            subplot_kw={'projection': ccrs.PlateCarree()},\n",
    "                            figsize=(6.7*ncols, 5.5*nrows))\n",
    "    if nrows * ncols > 1:\n",
    "        axs=axs.flatten()\n",
    "    else:\n",
    "        axs=[axs]\n",
    "\n",
    "    #fig = plt.figure(figsize=(20, 8))\n",
    "    #ax1 = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "    for iprod in range(nrows):\n",
    "        for itime in range(ncols):\n",
    "            ax1 = axs[itime + ncols * iprod]\n",
    "            time = plot_times[itime]\n",
    "            prod = type_d[iprod]\n",
    "            if sort:\n",
    "                arr = np.sort(data[prod][time], order='vals')\n",
    "            else:\n",
    "                arr = data[prod][time]\n",
    "            lats = arr['lat'] \n",
    "            lons = arr['lon'] \n",
    "            values = arr['vals']\n",
    "\n",
    "            prepare_layout(ax1, lon_limits, lat_limits)\n",
    "            if use_alpha:\n",
    "                m = max(np.max(values), -np.min(values))\n",
    "                alphas = [(v+m/4)/(m+m/4) for v in values]\n",
    "                alphas = [abs(a) for a in alphas]\n",
    "            else:\n",
    "                alphas = [1 for _ in values]\n",
    "\n",
    "            sctr = ax1.scatter(lons, lats, c=values,\n",
    "                               alpha = alphas,\n",
    "                               marker = 's', s =15, zorder=3,  \n",
    "                               vmin = clims[prod][0],\n",
    "                               vmax = clims[prod][1], \n",
    "                               cmap = 'jet')\n",
    "            for marker in markers:\n",
    "                ax1.scatter(marker['lon'], marker['lat'], \n",
    "                            marker='*', color=\"black\", s=400,\n",
    "                            zorder=5)\n",
    "            if iprod == 0:\n",
    "                ax1.set_title(time.strftime(TIME_FORMAT)[:-7]+'\\n'+prod)\n",
    "            else:\n",
    "                ax1.set_title('\\n'+prod)\n",
    "            if itime % ncols == ncols - 1:\n",
    "                cax = fig.add_axes([ax1.get_position().x1+0.01,\n",
    "                                    ax1.get_position().y0,\n",
    "                                    0.02,\n",
    "                                    ax1.get_position().height])\n",
    "                cbar = ax1.figure.colorbar(sctr, cax=cax)\n",
    "                cbar_label = clims[prod][2] + \"\\n\" if type_d == \"ROTI\" else clims[prod][2]\n",
    "                cbar.ax.set_ylabel(cbar_label, rotation=-90, va=\"bottom\")\n",
    "            directory = os.getcwd()\n",
    "            ax1.xaxis.set_ticks_position('none') \n",
    "            #If you want to save file uncomment next line\n",
    "            #plt.savefig(os.path.join(directory,time[:-7].replace(':','-')+'.png') , fmt = 'png')\n",
    "\n",
    "    if savefig:\n",
    "        plt.savefig(savefig)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "    #plt.tight_layout()    \n",
    "    plt.rcdefaults()\n",
    "\n",
    "\n",
    "#Plot data from map file\n",
    "def retrieve_data(file, type_d, times=[]):    \n",
    "    \"\"\"\n",
    "    Plotting data from map file\n",
    "    input - <file> string type name of file \n",
    "            <type_d> string type of data going to be plotted\n",
    "    output - figures\n",
    "    \"\"\"  \n",
    "    f_in = h5py.File(file, 'r')\n",
    "    lats = []\n",
    "    lons = []\n",
    "    values = []\n",
    "    data = {}\n",
    "    for str_time in list(f_in['data'])[:]:\n",
    "        time = datetime.strptime(str_time, TIME_FORMAT)\n",
    "        time = time.replace(tzinfo=time.tzinfo or _UTC)\n",
    "        if times and not time in times:\n",
    "            continue\n",
    "        data[time] = f_in['data'][str_time][:]\n",
    "    return data\n",
    "\n",
    "def _merge_structured_arrays(arrays):\n",
    "    ns = [len(array) for array in arrays]\n",
    "    array_out = arrays[0].copy()\n",
    "    array_out.resize(sum(ns))\n",
    "    N = ns[0]\n",
    "    for i in range(1, len(ns)):\n",
    "        array_out[N:N + ns[i]] = arrays[i]\n",
    "        N = N + ns[i]\n",
    "    return array_out\n",
    "\n",
    "def retrieve_data_multiple_source(files, type_d, times=[]):\n",
    "    datas = defaultdict(list)\n",
    "    for file in files:\n",
    "        file_data = retrieve_data(file, type_d, times=times)\n",
    "        for time, data in file_data.items():\n",
    "            datas[time].append(data)\n",
    "    for time in datas:\n",
    "        datas[time] = _merge_structured_arrays(datas[time])\n",
    "    return datas\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e3f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_maps(prod_files, prods, epc, clims=None, times=None, scale=1):\n",
    "    if clims:\n",
    "        C_LIMITS = clims\n",
    "    else:\n",
    "        C_LIMITS ={\n",
    "            'ROTI': [0,0.5*scale,'TECu/min'],\n",
    "            '2-10 minute TEC variations': [-0.4*scale,0.4*scale,'TECu'],\n",
    "            '10-20 minute TEC variations': [-0.6*scale,0.6*scale,'TECu'],\n",
    "            '20-60 minute TEC variations': [-1*scale,1*scale,'TECu'],\n",
    "            'tec': [0,50*scale,'TECu/min'],\n",
    "            'tec_adjusted': [0,50*scale,'TECu'],\n",
    "        }\n",
    "    if times:\n",
    "        pass\n",
    "    else:\n",
    "        times = [datetime(2023, 2, 6, 10, 25),\n",
    "                 datetime(2023, 2, 6, 10, 40),\n",
    "                 datetime(2023, 2, 6, 10, 45, 0)]\n",
    "    times = [t.replace(tzinfo=t.tzinfo or _UTC) for t in times]\n",
    "    for files in zip(*prod_files):\n",
    "        data = retrieve_data_multiple_source(files, prods[files[0]], times)\n",
    "        data = {prods[files[0]]: data}\n",
    "        plot_map(times, data, prods[files[0]],\n",
    "    #             use_alpha=True,\n",
    "                 lat_limits=(25, 50),\n",
    "                 lon_limits=(25, 50),\n",
    "                 sort=True,\n",
    "                 markers=[EPICENTERS['10:24']],\n",
    "                 clims=C_LIMITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0726e5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_maps([FILES_PRODUCT_10_24, TNPGN_FILES_PRODUCT_10_24], \n",
    "          FILES_PRODUCT_10_24, \n",
    "          EPICENTERS['10:24'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fe8991",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_maps([FILES_PRODUCT_10_24], \n",
    "          FILES_PRODUCT_10_24, \n",
    "          EPICENTERS['10:24'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125b5027",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_maps([TNPGN_FILES_PRODUCT_10_24], \n",
    "           TNPGN_FILES_PRODUCT_10_24, \n",
    "           EPICENTERS['10:24'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d871699",
   "metadata": {},
   "source": [
    "## Repeat plot for night quake\n",
    "\n",
    "Note we changed limits for color scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce9d8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [datetime(2023, 2, 6, 1, 17),\n",
    "         datetime(2023, 2, 6, 1, 32),\n",
    "         datetime(2023, 2, 6, 1, 37)]\n",
    "plot_maps([FILES_PRODUCT_01_17, TNPGN_FILES_PRODUCT_01_17], \n",
    "          FILES_PRODUCT_01_17, \n",
    "          EPICENTERS['01:17'], \n",
    "          times = times,\n",
    "          scale=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dafc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_LIMITS ={\n",
    "    'ROTI': [0,0.1,'TECu/min'],\n",
    "    '2-10 minute TEC variations': [-0.1,0.1,'TECu'],\n",
    "    '10-20 minute TEC variations': [-0.2,0.2,'TECu'],\n",
    "    '20-60 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    'tec': [0,50,'TECu/min'],\n",
    "    'tec_adjusted': [0,50,'TECu'],\n",
    "}\n",
    "\n",
    "times = [datetime(2023, 2, 6, 1, 17),\n",
    "         datetime(2023, 2, 6, 1, 32),\n",
    "         datetime(2023, 2, 6, 1, 37)]\n",
    "times = [t.replace(tzinfo=t.tzinfo or _UTC) for t in times]\n",
    "for f in FILES_PRODUCT_01_17:\n",
    "    data = retrieve_data(f, FILES_PRODUCT_01_17[f], times)\n",
    "    plot_map(times, data, FILES_PRODUCT_01_17[f],\n",
    "             lat_limits=(25, 50),\n",
    "             lon_limits=(25, 50),\n",
    "             markers=[EPICENTERS['01:17']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67914c55",
   "metadata": {},
   "source": [
    "# Lets examine the series (note: data load is commented)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c0a715",
   "metadata": {},
   "source": [
    "## Select sites and make proper structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da892d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sites_coords(local_file, exclude_sites = [],\n",
    "                    min_lat=-90, max_lat=90,\n",
    "                    min_lon=-180, max_lon=180,):    \n",
    "    f = h5py.File(local_file)\n",
    "    sites = list(f.keys())\n",
    "    coords = dict()\n",
    "    for site in sites:\n",
    "        if site in exclude_sites:\n",
    "            continue\n",
    "        latlon = f[site].attrs\n",
    "        slat = np.degrees(latlon['lat'])\n",
    "        slon = np.degrees(latlon['lon'])\n",
    "        if min_lat < slat < max_lat and min_lon < slon < max_lon:\n",
    "            coords[site] = dict()\n",
    "            coords[site]['lat'] = f[site].attrs['lat']\n",
    "            coords[site]['lon'] = f[site].attrs['lon']\n",
    "    f.close()\n",
    "    return coords\n",
    "\n",
    "def select_visible_sats_data(local_file, sites, tcheck):\n",
    "    f = h5py.File(local_file)\n",
    "    data = dict()\n",
    "    for site in sites:\n",
    "        data[site] = dict()\n",
    "        for sat in f[site].keys():\n",
    "            times = [datetime.utcfromtimestamp(t) for t in f[site][sat]['timestamp'][:]]\n",
    "            if tcheck in times:\n",
    "                data[site][sat] = {'time': times,\n",
    "                                   'tec':  f[site][sat]['tec'][:],\n",
    "                                   'roti': f[site][sat]['roti'][:],\n",
    "                                   'azimuth': f[site][sat]['azimuth'][:],\n",
    "                                   'elevation': f[site][sat]['elevation'][:]}\n",
    "    f.close()\n",
    "    return data\n",
    "\n",
    "def get_visible_sats_names(data):\n",
    "    sats = list()\n",
    "    for site in data:\n",
    "        for sat in data[site]:\n",
    "            sats.append(sat)\n",
    "    return list(set(sats))\n",
    "\n",
    "\n",
    "def select_sats_by_params(data, sats, tcheck, min_sats_number=5, **kwargs):\n",
    "    min_elevation = np.radians(kwargs.get('min_elevation', 10))\n",
    "    min_azimuth = np.radians(kwargs.get('min_elevation', 0))\n",
    "    max_azimuth = np.radians(kwargs.get('min_elevation', 360))\n",
    "    sats_count = {sat: 0 for sat in set(sats)}\n",
    "    for site in data:\n",
    "        for sat in data[site]:\n",
    "            if sat not in sats:\n",
    "                continue\n",
    "            azs = data[site][sat]['azimuth']\n",
    "            els = data[site][sat]['elevation']\n",
    "            times = data[site][sat]['time']\n",
    "            if tcheck in times:\n",
    "                ind = times.index(tcheck)\n",
    "                if not(min_azimuth < azs[ind] < max_azimuth):\n",
    "                    continue\n",
    "                if not(els[ind] > min_elevation):\n",
    "                    continue\n",
    "                sats_count[sat] = sats_count[sat] + 1\n",
    "    sats_count = {sat: c for sat, c in sats_count.items() if c > min_sats_number}\n",
    "    return sats_count\n",
    "\n",
    "def select_reoder_data(data, sats_count):\n",
    "    _data = {sat: list() for sat in sats_count}\n",
    "    for site in data:\n",
    "        for sat in sats_count:\n",
    "            if not sat in data[site]:\n",
    "                continue\n",
    "            _data[sat].append(data[site][sat])\n",
    "            _data[sat][-1]['site'] = site\n",
    "    return _data\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2b9556",
   "metadata": {},
   "source": [
    "## Plot function for series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddce774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_sat(data_plot, sat, epc, plot_product, \n",
    "                    limits=(3600,3600),\n",
    "                    shift=0.5,\n",
    "                    site_labels=False):\n",
    "    i = 0\n",
    "    plt.figure(figsize=(6, 13))\n",
    "    plt.rcParams.update(DEFAULT_PARAMS)\n",
    "    plot_ax = plt.axes()\n",
    "    \n",
    "    sites = list()\n",
    "    locs = list()\n",
    "    for d in data_plot[sat]:\n",
    "        _t = d['time']\n",
    "        _val = d[plot_product]\n",
    "        #for i in range(len(_t)-1):\n",
    "            #if d['times'][i] - d['times'][i+1] > timedelta(0, 30):\n",
    "            #    _t[i] = None\n",
    "        plt.plot(_t, _val+i*shift, marker='.')\n",
    "        locs.append(i*shift)\n",
    "        i = i + 1\n",
    "        plt.axvline(x=epc['time'], color='black', linewidth=3)\n",
    "        sites.append(d['site'])\n",
    "    print('Sorted', sites)\n",
    "    plt.xlim(epc['time'] -timedelta(0, limits[0]),\n",
    "             epc['time'] +timedelta(0, limits[1]),)\n",
    "    # to make grid lines on top and bottom\n",
    "    locs = [-2*shift, -shift] + locs + [i * shift, (i+1) * shift]\n",
    "    sites = ['']*2 + sites + ['']*2\n",
    "    if site_labels:\n",
    "        plt.yticks(locs, sites)\n",
    "    plt.ylim(-2 * shift, (i+1)*shift )\n",
    "    plot_ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M\"))\n",
    "    plt.title('Satellite '+sat)\n",
    "    plt.grid()\n",
    "    plt.xlabel('UTC for February 6, 2023')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b2a695",
   "metadata": {},
   "source": [
    "## Calculate rate of tec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b647bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtecs(data,\n",
    "              sort_type='none', threshold = 0.5,\n",
    "              start_time = datetime(2023, 2, 6, 10,25),\n",
    "              end_time = datetime(2023, 2, 6, 10,46),\n",
    "              sat = 'E08', \n",
    "              threshold_type=\"all\"):\n",
    "\n",
    "    dtecs = dict()\n",
    "    dtecs[sat] = list()\n",
    "    for _data in data[sat]:\n",
    "        if not (start_time in _data['time'] and\n",
    "                end_time in _data['time']):\n",
    "            continue\n",
    "        start = _data['time'].index(start_time)\n",
    "        end = _data['time'].index(end_time)\n",
    "        tec = _data['tec'][start: end]\n",
    "        dtec = tec - _data['tec'][start-1: end-1]\n",
    "        dtec = dtec - np.average(dtec)\n",
    "        take = False\n",
    "        threshold_index = None\n",
    "        for itec, d in enumerate(dtec[1:]):\n",
    "            take = ((threshold_type == 'all' and abs(d) >= threshold) or\n",
    "                    (threshold_type == 'max' and d >= threshold) or\n",
    "                    (threshold_type == 'min' and d <= -threshold))\n",
    "            if take:\n",
    "                threshold_index = itec+1\n",
    "                break\n",
    "        if take:\n",
    "            tec = [0, ]\n",
    "            for dt in dtec[1:]:\n",
    "                tec.append(dt + tec[-1])\n",
    "            tec = np.array(tec)\n",
    "            dtecs[sat].append({'time': _data['time'][start: end],\n",
    "                              'dtec': dtec,\n",
    "                              'tec': tec,\n",
    "                              'roti': _data['roti'][start: end],\n",
    "                              'site': _data['site'][:],\n",
    "                              'th_elevation':  _data['elevation'][start: end][threshold_index],\n",
    "                              'th_azimuth':  _data['azimuth'][start: end][threshold_index],\n",
    "                              'th_time':  _data['time'][start: end][threshold_index],\n",
    "                              'th_index': threshold_index})\n",
    "\n",
    "    if sort_type in ['max', 'min']:\n",
    "        max_times = []\n",
    "        for i, dtec in enumerate(dtecs[sat]):\n",
    "            vals = dtec['dtec']\n",
    "            for j in range(1, len(vals) - 1):\n",
    "                t = dtec['time'][j]\n",
    "                d = dtec['dtec'][j]\n",
    "                cond = False\n",
    "                if sort_type=='max':\n",
    "                    cond = (d >= threshold /2 and d > vals[j-1] and d > vals[j+1])\n",
    "                if sort_type=='min':\n",
    "                    cond = (d <= -threshold /2 and d < vals[j-1] and d < vals[j+1])\n",
    "                if cond:\n",
    "                    max_times.append((i, t))\n",
    "                    dtec['max_time'] = t\n",
    "                    #print(d, t)\n",
    "                    break\n",
    "            else:\n",
    "                dtec['max_time'] = start_time\n",
    "\n",
    "        dtecs[sat].sort(key = lambda x: x['max_time'])\n",
    "    return dtecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2213ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_file = 'tnpgn_2023-02-06.h5'\n",
    "tcheck = datetime(2023, 2, 6, 10, 38)\n",
    "#url = 'https://simurg.iszf.irk.ru/gen_file?data=obs&date=2023-02-06'\n",
    "#response = requests.get(url)\n",
    "#open(local_file, \"wb\").write(response.content)\n",
    "coords = get_sites_coords(local_file, exclude_sites=['guru'])\n",
    "sites = [site for site in coords]\n",
    "data = select_visible_sats_data(local_file, sites, tcheck = tcheck)\n",
    "visible_sats = get_visible_sats_names(data)\n",
    "sats_count = select_sats_by_params(data, visible_sats, tcheck)\n",
    "_data = select_reoder_data(data, sats_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e199eb3",
   "metadata": {},
   "source": [
    "## Find satellite with max effects by means of ROTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d41f3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_file = 'region_2023-02-06.h5'\n",
    "tcheck = datetime(2023, 2, 6, 10, 38)\n",
    "#url = 'https://simurg.iszf.irk.ru/gen_file?data=obs&date=2023-02-06'\n",
    "#response = requests.get(url)\n",
    "#open(local_file, \"wb\").write(response.content)\n",
    "coords = get_sites_coords(local_file, exclude_sites=['guru'])\n",
    "sites = [site for site in coords]\n",
    "data = select_visible_sats_data(local_file, sites, tcheck = tcheck)\n",
    "visible_sats = get_visible_sats_names(data)\n",
    "sats_count = select_sats_by_params(data, visible_sats, tcheck)\n",
    "_data = select_reoder_data(data, sats_count)\n",
    "sat = 'E08'\n",
    "print(len(_data))\n",
    "dtecs = get_dtecs(_data, sort_type='max', sat=sat, threshold=0.5)\n",
    "sites = []\n",
    "for d in dtecs[sat]:\n",
    "    sites.append(d['site'])\n",
    "print(sites)\n",
    "plot_single_sat(dtecs, sat, EPICENTERS['10:24'], 'dtec',\n",
    "                limits=(0,1200),\n",
    "                shift=0.5, site_labels=True)\n",
    "plot_single_sat(dtecs, sat, EPICENTERS['10:24'], 'tec',\n",
    "                limits=(0,1200),\n",
    "                shift=0.5, site_labels=True)\n",
    "plot_single_sat(dtecs, sat, EPICENTERS['10:24'], 'roti',\n",
    "                limits=(0,1200),\n",
    "                shift=0.5, site_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042ffbe3",
   "metadata": {},
   "source": [
    "# Individual line-of-sight velocity estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf8eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import pi, sin, cos, arccos, arcsin\n",
    "from scipy.stats import norm\n",
    "\n",
    "RE_meters = 6371000\n",
    "\n",
    "def sub_ionospheric(s_lat, s_lon, hm, az, el, R=RE_meters):\n",
    "    \"\"\"\n",
    "    Calculates subionospheric point and delatas from site\n",
    "    Parameters:\n",
    "        s_lat, slon - site latitude and longitude in radians\n",
    "        hm - ionposheric maximum height (meters)\n",
    "        az, el - azimuth and elevation of the site-sattelite line of sight in\n",
    "            radians\n",
    "        R - Earth radius (meters)\n",
    "    \"\"\"\n",
    "    #TODO use meters\n",
    "    psi = pi / 2 - el - arcsin(cos(el) * R / (R + hm))\n",
    "    lat = bi = arcsin(sin(s_lat) * cos(psi) + cos(s_lat) * sin(psi) * cos(az))\n",
    "    lon = sli = s_lon + arcsin(sin(psi) * sin(az) / cos(bi))\n",
    "\n",
    "    lon = lon - 2 * pi if lon > pi else lon\n",
    "    lon = lon + 2 * pi if lon < -pi else lon\n",
    "    return lat, lon\n",
    "\n",
    "\n",
    "def great_circle_distance_numpy(late, lone, latp, lonp, R=RE_meters):\n",
    "    \"\"\"\n",
    "    Calculates arc length. Uses numpy arrays\n",
    "    late, latp: double\n",
    "        latitude in radians\n",
    "    lone, lonp: double\n",
    "        longitudes in radians\n",
    "    R: double\n",
    "        radius\n",
    "    \"\"\"\n",
    "    lone[np.where(lone < 0)] = lone[np.where(lone < 0)] + 2*pi\n",
    "    lonp[np.where(lonp < 0)] = lonp[np.where(lonp < 0)] + 2*pi\n",
    "    dlon = lonp - lone\n",
    "    inds = np.where((dlon > 0) & (dlon > pi)) \n",
    "    dlon[inds] = 2 * pi - dlon[inds]\n",
    "    dlon[np.where((dlon < 0) & (dlon < -pi))] += 2 * pi\n",
    "    dlon[np.where((dlon < 0) & (dlon < -pi))] = -dlon[np.where((dlon < 0) & (dlon < -pi))]\n",
    "    cosgamma = sin(late) * sin(latp) + cos(late) * cos(latp) * cos(dlon)\n",
    "    return R * arccos(cosgamma)\n",
    "\n",
    "def calculate_distances_from_epicenter(data, coords, sat, elat, elon):\n",
    "    for _data in data[sat]:\n",
    "        sites_coords = coords[_data['site']]\n",
    "        el = _data['th_elevation']\n",
    "        az = _data['th_azimuth']\n",
    "        slat = sites_coords['lat']\n",
    "        slon = sites_coords['lon']\n",
    "        sip_lat, sip_lon = sub_ionospheric(slat, slon, hm=300000, az=az, el=el)\n",
    "        d = great_circle_distance_numpy(np.array([sip_lat]), np.array([sip_lon]), \n",
    "                                        np.array([elat]), np.array([elat]),\n",
    "                                        R = RE_meters + 300000)\n",
    "        _data['distance'] = d[0]\n",
    "\n",
    "        \n",
    "def fit_and_plot_distribution(data, xmin=0, xmax=4000):\n",
    "    print(len(data))\n",
    "    plt.figure(figsize=(18, 9))\n",
    "    mu, std = norm.fit(data)\n",
    "    plt.grid()\n",
    "    # Plot the histogram.\n",
    "    counts, edges, bars = plt.hist(data, bins=20, density=True, alpha=0.6, color='g')\n",
    "    #plt.bar_label(bars)\n",
    "    y = ((1 / (np.sqrt(2 * np.pi) * std)) *\n",
    "         np.exp(-0.5 * (1 / std * (edges - mu))**2))\n",
    "    # Plot the PDF.\n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    p = norm.pdf(x, mu, std) # * len(data) * len(data)\n",
    "    plt.plot(x, p, 'k', linewidth=3, color='black')\n",
    "    title = \"Fit results: mean = %.2f m/s,  STD = %.2f m/s\"  % (mu, std)\n",
    "    plt.xlabel('velocity, m/s')\n",
    "\n",
    "    ytick = [i / 10000 * 1.03213 for i in range(0, 13, 2)]\n",
    "    ylables = [round(i) for i in range(0, 13, 2)] \n",
    "    plt.yticks(ytick, ylables)\n",
    "    plt.ylabel('Occuranes')\n",
    "    plt.title(title)\n",
    "    plt.ylim(0, 13 / 10000 * 1.03213)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9ec90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_file = 'region_2023-02-06.h5'\n",
    "tcheck = datetime(2023, 2, 6, 10, 38)\n",
    "#url = 'https://simurg.iszf.irk.ru/gen_file?data=obs&date=2023-02-06'\n",
    "#response = requests.get(url)\n",
    "#open(local_file, \"wb\").write(response.content)\n",
    "coords = get_sites_coords(local_file, exclude_sites=['guru'])\n",
    "sites = [site for site in coords]\n",
    "data = select_visible_sats_data(local_file, sites, tcheck = tcheck)\n",
    "visible_sats = get_visible_sats_names(data)\n",
    "sats_count = select_sats_by_params(data, visible_sats, tcheck)\n",
    "_data = select_reoder_data(data, sats_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03f7f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sat='G17'\n",
    "dtecs = get_dtecs(_data, sort_type='max', sat=sat, threshold=0.25, threshold_type='min')\n",
    "sites = []\n",
    "for d in dtecs[sat]:\n",
    "    sites.append(d['site'])\n",
    "print(sites)\n",
    "plot_single_sat(dtecs, sat, EPICENTERS['10:24'], 'dtec',\n",
    "                limits=(0,1200),\n",
    "                shift=0.5, site_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3a4856",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_file = 'region_2023-02-06.h5'\n",
    "tcheck = datetime(2023, 2, 6, 10, 38)\n",
    "#url = 'https://simurg.iszf.irk.ru/gen_file?data=obs&date=2023-02-06'\n",
    "#response = requests.get(url)\n",
    "#open(local_file, \"wb\").write(response.content)\n",
    "coords = get_sites_coords(local_file, exclude_sites=['guru'])\n",
    "sites = [site for site in coords]\n",
    "data = select_visible_sats_data(local_file, sites, tcheck = tcheck)\n",
    "visible_sats = get_visible_sats_names(data)\n",
    "sats_count = select_sats_by_params(data, visible_sats, tcheck)\n",
    "_data = select_reoder_data(data, sats_count)\n",
    "\n",
    "\n",
    "sats = ['G17', 'G14', 'G24', 'E08']\n",
    "\n",
    "for start_time in [datetime(2023, 2, 6, 10, 35, 0) + timedelta(0, 30 * i) for i in range(1)]:\n",
    "    deltas = list()\n",
    "    dists = list()\n",
    "    velocities = list()\n",
    "\n",
    "    for sat in sats:\n",
    "        dtecs = get_dtecs(_data, sort_type='max', sat=sat, threshold=0.25, threshold_type='min')\n",
    "        elat = np.radians(EPICENTERS['10:24']['lat'])\n",
    "        elon = np.radians(EPICENTERS['10:24']['lon'])\n",
    "        calculate_distances_from_epicenter(dtecs, coords, sat, elat, elon)\n",
    "        #plot_single_sat(dtecs, sat, EPICENTERS['10:24'], 'dtec',\n",
    "        #                limits=(0,1200),\n",
    "        #                shift=0.5, site_labels=True)\n",
    "        for data in dtecs[sat]:\n",
    "            delta  = (data['th_time'] - start_time )/ timedelta(0, 1)\n",
    "            if delta == 0.0:\n",
    "                continue\n",
    "            velocity = data['distance'] / delta\n",
    "            if velocity < 0 or velocity > 4000:\n",
    "                continue\n",
    "            deltas.append(delta)\n",
    "            dists.append(data['distance'])\n",
    "            velocities.append(velocity)\n",
    "    print(start_time)\n",
    "    fit_and_plot_distribution(velocities)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d31b637",
   "metadata": {},
   "source": [
    "# Major effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d30b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_LIMITS ={\n",
    "    'ROTI': [0,0.5,'TECu/min'],\n",
    "    '2-10 minute TEC variations': [-0.4,0.4,'TECu'],\n",
    "    '10-20 minute TEC variations': [-0.2,0.2,'TECu'],\n",
    "    '20-60 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    'tec': [0,50,'TECu/min'],\n",
    "    'tec_adjusted': [0,50,'TECu'],\n",
    "}\n",
    "\n",
    "times = [datetime(2023, 2, 6, 10, 33, 0) + timedelta(0, 30) * i for i in range(18)]\n",
    "#_FILES = dict()\n",
    "#_FILES[\"roti_10_24.h5\"] = FILES_PRODUCT_10_24[\"roti_10_24.h5\"]\n",
    "#_FILES[\"dtec_2_10_10_24.h5\"] = FILES_PRODUCT_10_24[\"dtec_2_10_10_24.h5\"]\n",
    "times = [t.replace(tzinfo=t.tzinfo or _UTC) for t in times]\n",
    "prod_files = [FILES_PRODUCT_10_24, TNPGN_FILES_PRODUCT_10_24]\n",
    "#for f in _FILES:\n",
    "for files in zip(*prod_files):\n",
    "    for t in times:\n",
    "        #data = retrieve_data(f, _FILES[f], [t])\n",
    "        prod = FILES_PRODUCT_10_24[files[0]]\n",
    "        data = retrieve_data_multiple_source(files, prod, [t])\n",
    "        data = {prod: data}\n",
    "        plot_map([t], data, prod,\n",
    "                 lat_limits=(25, 50),\n",
    "                 lon_limits=(25, 50),\n",
    "                 markers=[EPICENTERS['10:24']],\n",
    "                 sort=True,\n",
    "                 ncols=1,\n",
    "                 clims=C_LIMITS)\n",
    "        break # ROMOVE TO GET ALL FIGUREs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f06cb96",
   "metadata": {},
   "source": [
    "## Save plots to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3167b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_LIMITS ={\n",
    "    'ROTI': [0,0.5,'TECu/min'],\n",
    "    '2-10 minute TEC variations': [-0.4,0.4,'TECu'],\n",
    "    '10-20 minute TEC variations': [-0.2,0.2,'TECu'],\n",
    "    '20-60 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    'tec': [0,50,'TECu/min'],\n",
    "    'tec_adjusted': [0,50,'TECu'],\n",
    "}\n",
    "\n",
    "times = [datetime(2023, 2, 6, 10, 20, 0) + timedelta(0, 30) * i for i in range(80)]\n",
    "#_FILES = dict()\n",
    "#_FILES[\"roti_10_24.h5\"] = FILES_PRODUCT_10_24[\"roti_10_24.h5\"]\n",
    "#_FILES[\"dtec_2_10_10_24.h5\"] = FILES_PRODUCT_10_24[\"dtec_2_10_10_24.h5\"]\n",
    "times = [t.replace(tzinfo=t.tzinfo or _UTC) for t in times]\n",
    "prod_files = [FILES_PRODUCT_10_24, TNPGN_FILES_PRODUCT_10_24]\n",
    "#for f in _FILES:\n",
    "for t in times:\n",
    "    _data = dict()\n",
    "    prods = list()\n",
    "    for files in zip(*prod_files):\n",
    "        #data = retrieve_data(f, _FILES[f], [t])\n",
    "        prod = FILES_PRODUCT_10_24[files[0]]\n",
    "        prods.append(prod)\n",
    "        data = retrieve_data_multiple_source(files, prod, [t])\n",
    "        _data[FILES_PRODUCT_10_24[files[0]]] = data\n",
    "    plot_map([t], _data, prods,\n",
    "             lat_limits=(25, 50),\n",
    "             lon_limits=(25, 50),\n",
    "             markers=[EPICENTERS['10:24']],\n",
    "             sort=True,\n",
    "             ncols=1,\n",
    "             nrows=4,\n",
    "             savefig=f\"{t}\",\n",
    "             clims=C_LIMITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b33cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_LIMITS ={\n",
    "    'ROTI': [0,0.2,'TECu/min'],\n",
    "    '2-10 minute TEC variations': [-0.1,0.1,'TECu'],\n",
    "    '10-20 minute TEC variations': [-0.2,0.2,'TECu'],\n",
    "    '20-60 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    'tec': [0,50,'TECu/min'],\n",
    "    'tec_adjusted': [0,50,'TECu'],\n",
    "}\n",
    "\n",
    "times = [datetime(2023, 2, 6, 1, 10, 0) + timedelta(0, 30) * i for i in range(80)]\n",
    "#_FILES = dict()\n",
    "#_FILES[\"roti_01_17.h5\"] = FILES_PRODUCT_01_17[\"roti_01_17.h5\"]\n",
    "#_FILES[\"dtec_2_10_01_17.h5\"] = FILES_PRODUCT_01_17[\"dtec_2_10_01_17.h5\"]\n",
    "prod_files = [FILES_PRODUCT_01_17, TNPGN_FILES_PRODUCT_01_17]\n",
    "times = [t.replace(tzinfo=t.tzinfo or _UTC) for t in times]\n",
    "#for f in _FILES:\n",
    "for files in zip(*prod_files):\n",
    "    for t in times:\n",
    "        #data = retrieve_data(f, _FILES[f], [t])\n",
    "        prod = FILES_PRODUCT_01_17[files[0]]\n",
    "        data = retrieve_data_multiple_source(files, prod, [t])\n",
    "\n",
    "        plot_map([t], data, prod,\n",
    "                 lat_limits=(25, 50),\n",
    "                 lon_limits=(25, 50),\n",
    "                 markers=[EPICENTERS['01:17']],\n",
    "                 sort=True,\n",
    "                 ncols=1,\n",
    "                 savefig=f\"{prod}_{t}\",\n",
    "                 clims=C_LIMITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ddbaef",
   "metadata": {},
   "source": [
    "# Distance time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e099f1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_dist_time(data, eq_location, direction='all'):\n",
    "    x, y, c = [], [], []\n",
    "    for time, map_data in data.items():\n",
    "        lats = np.radians(map_data[\"lat\"][:])\n",
    "        lons = np.radians(map_data[\"lon\"][:])\n",
    "        vals = map_data[\"vals\"][:]\n",
    "        _eq_location = {}\n",
    "        _eq_location[\"lat\"] = np.radians(eq_location[\"lat\"])\n",
    "        _eq_location[\"lon\"] = np.radians(eq_location[\"lon\"])\n",
    "        if direction == \"all\":\n",
    "            inds = np.isreal(lats)\n",
    "        elif direction == \"north\":\n",
    "            inds = lats >= _eq_location[\"lat\"]\n",
    "        elif direction == \"south\":\n",
    "            inds = lats <= _eq_location[\"lat\"]\n",
    "        elif direction == \"east\":\n",
    "            inds = lats >= _eq_location[\"lon\"]\n",
    "        elif direction == \"west\":\n",
    "            inds = lats <= _eq_location[\"lon\"]\n",
    "        else:\n",
    "            inds = numpy.isreal(lats)\n",
    "        lats = lats[inds]\n",
    "        lons = lons[inds]\n",
    "        vals = vals[inds]\n",
    "        plats = np.zeros_like(lats)\n",
    "        plons = np.zeros_like(lons)\n",
    "        plats[:] = _eq_location[\"lat\"]\n",
    "        plons[:] = _eq_location[\"lon\"]\n",
    "\n",
    "        dists = great_circle_distance_numpy(lats,lons, \n",
    "                                            plats, plons)\n",
    "        \n",
    "\n",
    "        x.extend([time] * len(vals))\n",
    "        y.extend(dists / 1000)\n",
    "        c.extend(vals)\n",
    "    return x, y, c\n",
    "\n",
    "def plot_distance_time(x, y, c, ptype, sort = True, line=dict(), clims=C_LIMITS, dmax=1750):\n",
    "    c_abs = [abs(_c) for _c in c]\n",
    "    if sort:    \n",
    "        x = [i for _, i in sorted(zip(c_abs, x))]\n",
    "        y = [i for _, i in sorted(zip(c_abs, y))]\n",
    "        c = [i for _, i in sorted(zip(c_abs, c))]\n",
    "        #x = [i for _, i in sorted(zip(c, x))]\n",
    "        #y = [i for _, i in sorted(zip(c, y))]\n",
    "        #c.sort()\n",
    "\n",
    "    times = [t for t in data]\n",
    "    times.sort()\n",
    "    plt.figure(figsize=(18, 5))\n",
    "    plt.rcParams.update(DEFAULT_PARAMS)\n",
    "    plot_ax = plt.axes()\n",
    "    #c[c<0.1] = np.nan\n",
    "    plt.scatter(x, y, c=c, cmap='jet')\n",
    "    cbar = plt.colorbar()\n",
    "    plt.clim(clims[ptype][0], clims[ptype][1])\n",
    "    plt.ylabel('Distance, km')\n",
    "    plt.xlabel('UTC for February 6, 2023')\n",
    "    print(times[0], times[-1])\n",
    "    plt.xlim(times[0], times[-1])\n",
    "    plt.ylim(0, dmax)\n",
    "    # plot vertical lines for earthquake times\n",
    "    for epc, params in EPICENTERS.items():\n",
    "        plt.axvline(x=params['time'], color='black', linewidth=3)\n",
    "    cbar.ax.set_ylabel( clims[ptype][2], rotation=-90, va=\"bottom\")\n",
    "    plot_ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M\"))\n",
    "    \n",
    "def plot_line(velocity, start, style='solid'):\n",
    "    timestep = 30\n",
    "    line = [velocity * timestep * i for i in range(13)]\n",
    "    dtimes = [start + i * timedelta(0, timestep) for i in range(13)]\n",
    "    plt.plot(dtimes, line, linestyle=style, color='black', zorder=5, linewidth=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a34a260",
   "metadata": {},
   "source": [
    "## Distance time for 10:24 UT quake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9333367",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_LIMITS ={\n",
    "    'ROTI': [-0,0.5,'TECu/min\\n'],\n",
    "    '2-10 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    '10-20 minute TEC variations': [-0.8,0.8,'TECu'],\n",
    "    '20-60 minute TEC variations': [-1.0,1.0,'TECu'],\n",
    "    'tec': [0,50,'TECu/min'],\n",
    "    'tec_adjusted': [0,50,'TECu'],\n",
    "}\n",
    "\n",
    "eq_location = EPICENTERS['10:24']\n",
    "\n",
    "data = retrieve_data(\"roti_10_24.h5\", \"ROTI\")\n",
    "x, y, c = get_dist_time(data, eq_location)\n",
    "plot_distance_time(x, y, c, \"ROTI\", clims=C_LIMITS)\n",
    "plot_line(2.000, datetime(2023, 2, 6, 10, 35))\n",
    "\n",
    "data = retrieve_data(\"dtec_2_10_10_24.h5\", \"2-10 minute TEC variations\")\n",
    "x, y, c = get_dist_time(data, eq_location)\n",
    "plot_distance_time(x, y, c, \"2-10 minute TEC variations\", clims=C_LIMITS)\n",
    "plot_line(1.500, datetime(2023, 2, 6, 10, 32, 30), style='dashed')\n",
    "plot_line(1.300, datetime(2023, 2, 6, 10, 34, 30))\n",
    "plot_line(0.900, datetime(2023, 2, 6, 10, 37), style='dotted')\n",
    "\n",
    "data = retrieve_data(\"dtec_10_20_10_24.h5\", \"10-20 minute TEC variations\")\n",
    "x, y, c = get_dist_time(data, eq_location)\n",
    "plot_distance_time(x, y, c, \"10-20 minute TEC variations\", clims=C_LIMITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b651b6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_LIMITS ={\n",
    "    'ROTI': [-0,0.5,'TECu/min\\n'],\n",
    "    '2-10 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    '10-20 minute TEC variations': [-0.8,0.8,'TECu'],\n",
    "    '20-60 minute TEC variations': [-1.0,1.0,'TECu'],\n",
    "    'tec': [0,50,'TECu/min'],\n",
    "    'tec_adjusted': [0,50,'TECu'],\n",
    "}\n",
    "\n",
    "eq_location = EPICENTERS['10:24']\n",
    "\n",
    "data = retrieve_data_multiple_source([\"roti_10_24.h5\", \"tnpgn_roti_10_24.h5\"], \n",
    "                                      \"ROTI\")\n",
    "x, y, c = get_dist_time(data, eq_location)\n",
    "plot_distance_time(x, y, c, \"ROTI\")\n",
    "plot_line(2.000, datetime(2023, 2, 6, 10, 35))\n",
    "\n",
    "data = retrieve_data_multiple_source([\"dtec_2_10_10_24.h5\", \"tnpgn_dtec_2_10_10_24.h5\"], \n",
    "                                      \"2-10 minute TEC variations\")\n",
    "x, y, c = get_dist_time(data, eq_location)\n",
    "plot_distance_time(x, y, c, \"2-10 minute TEC variations\")\n",
    "plot_line(1.500, datetime(2023, 2, 6, 10, 32, 30), style='dashed')\n",
    "plot_line(1.300, datetime(2023, 2, 6, 10, 34, 30))\n",
    "plot_line(0.900, datetime(2023, 2, 6, 10, 37), style='dotted')\n",
    "\n",
    "data = retrieve_data_multiple_source([\"dtec_10_20_10_24.h5\", \"tnpgn_dtec_10_20_10_24.h5\"], \n",
    "                                      \"10-20 minute TEC variations\")\n",
    "x, y, c = get_dist_time(data, eq_location)\n",
    "plot_distance_time(x, y, c, \"10-20 minute TEC variations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff5f9b6",
   "metadata": {},
   "source": [
    "## Compare 01:17 and 10:24 quake using ROTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e5ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_LIMITS ={\n",
    "    'ROTI': [-0,0.5,'TECu/min\\n'],\n",
    "    '2-10 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    '10-20 minute TEC variations': [-0.4,0.4,'TECu'],\n",
    "    '20-60 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    'tec': [0,50,'TECu/min'],\n",
    "    'tec_adjusted': [0,50,'TECu'],\n",
    "}\n",
    "\n",
    "eq_location = EPICENTERS['10:24']\n",
    "\n",
    "data = retrieve_data(\"roti_10_24.h5\", \"ROTI\")\n",
    "x, y, c = get_dist_time(data, eq_location)\n",
    "plot_distance_time(x, y, c, \"ROTI\")\n",
    "\n",
    "C_LIMITS ={\n",
    "    'ROTI': [0, 0.3,'TECu/min\\n'],\n",
    "    '2-10 minute TEC variations': [-0.4,0.4,'TECu'],\n",
    "    '10-20 minute TEC variations': [-0.4,0.4,'TECu'],\n",
    "    '20-60 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    'tec': [0,50,'TECu/min'],\n",
    "    'tec_adjusted': [0,50,'TECu'],\n",
    "}\n",
    "\n",
    "eq_location = EPICENTERS['01:17']\n",
    "\n",
    "data = retrieve_data(\"roti_01_17.h5\", \"ROTI\")\n",
    "times = [t for t in data]\n",
    "times.sort()\n",
    "data = {t: data[t] for t in times[120:]} # start from 01:00 UT\n",
    "x, y, c = get_dist_time(data, eq_location)\n",
    "plot_distance_time(x, y, c, \"ROTI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2441e795",
   "metadata": {},
   "source": [
    "## Compare 01:17 and 10:24 quake using ROTI 2-10 minute variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2293fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_LIMITS ={\n",
    "    'ROTI': [-0,0.6,'TECu/min\\n'],\n",
    "    '2-10 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    '10-20 minute TEC variations': [-0.4,0.4,'TECu'],\n",
    "    '20-60 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    'tec': [0,50,'TECu/min'],\n",
    "    'tec_adjusted': [0,50,'TECu'],\n",
    "}\n",
    "\n",
    "eq_location = EPICENTERS['10:24']\n",
    "\n",
    "data = retrieve_data_multiple_source([\"dtec_2_10_10_24.h5\", \"tnpgn_dtec_2_10_10_24.h5\"], \n",
    "                                      \"2-10 minute TEC variations\")\n",
    "x, y, c = get_dist_time(data, eq_location)\n",
    "plot_distance_time(x, y, c, \"2-10 minute TEC variations\", clims=C_LIMITS)\n",
    "plot_line(1.500, datetime(2023, 2, 6, 10, 32, 30), style='dashed')\n",
    "plot_line(1.300, datetime(2023, 2, 6, 10, 34, 30))\n",
    "plot_line(0.900, datetime(2023, 2, 6, 10, 37), style='dotted')\n",
    "\n",
    "C_LIMITS ={\n",
    "    'ROTI': [0, 0.15,'TECu/min\\n'],\n",
    "    '2-10 minute TEC variations': [-0.2,0.2,'TECu'],\n",
    "    '10-20 minute TEC variations': [-0.2,0.2,'TECu'],\n",
    "    '20-60 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    'tec': [0,50,'TECu/min'],\n",
    "    'tec_adjusted': [0,50,'TECu'],\n",
    "}\n",
    "\n",
    "eq_location = EPICENTERS['01:17']\n",
    "\n",
    "data = retrieve_data_multiple_source([\"dtec_2_10_01_17.h5\", \"tnpgn_dtec_2_10_01_17.h5\"], \n",
    "                                      \"2-10 minute TEC variations\")\n",
    "times = [t for t in data]\n",
    "times.sort()\n",
    "data = {t: data[t] for t in times[120:]} # start from 01:00 UT\n",
    "x, y, c = get_dist_time(data, eq_location)\n",
    "plot_distance_time(x, y, c, \"2-10 minute TEC variations\", clims=C_LIMITS)\n",
    "plot_line(1.500, datetime(2023, 2, 6, 1, 26, 30), style='dashed')\n",
    "plot_line(1.300, datetime(2023, 2, 6, 1, 29))\n",
    "plot_line(0.900, datetime(2023, 2, 6, 1, 32), style='dotted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ada58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_LIMITS ={\n",
    "    'ROTI': [-0,0.6,'TECu/min\\n'],\n",
    "    '2-10 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    '10-20 minute TEC variations': [-0.4,0.4,'TECu'],\n",
    "    '20-60 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    'tec': [0,50,'TECu/min'],\n",
    "    'tec_adjusted': [0,50,'TECu'],\n",
    "}\n",
    "\n",
    "eq_location = EPICENTERS['10:24']\n",
    "\n",
    "data = retrieve_data(\"dtec_2_10_10_24.h5\", \"2-10 minute TEC variations\")\n",
    "x, y, c = get_dist_time(data, eq_location)\n",
    "plot_distance_time(x, y, c, \"2-10 minute TEC variations\", clims=C_LIMITS)\n",
    "plot_line(1.500, datetime(2023, 2, 6, 10, 32, 30), style='dashed')\n",
    "plot_line(1.300, datetime(2023, 2, 6, 10, 34, 30))\n",
    "plot_line(0.900, datetime(2023, 2, 6, 10, 37), style='dotted')\n",
    "\n",
    "C_LIMITS ={\n",
    "    'ROTI': [0, 0.15,'TECu/min\\n'],\n",
    "    '2-10 minute TEC variations': [-0.2,0.2,'TECu'],\n",
    "    '10-20 minute TEC variations': [-0.2,0.2,'TECu'],\n",
    "    '20-60 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    'tec': [0,50,'TECu/min'],\n",
    "    'tec_adjusted': [0,50,'TECu'],\n",
    "}\n",
    "\n",
    "eq_location = EPICENTERS['01:17']\n",
    "\n",
    "data = retrieve_data(\"dtec_2_10_01_17.h5\", \"2-10 minute TEC variations\")\n",
    "times = [t for t in data]\n",
    "times.sort()\n",
    "data = {t: data[t] for t in times[120:]} # start from 01:00 UT\n",
    "x, y, c = get_dist_time(data, eq_location)\n",
    "plot_distance_time(x, y, c, \"2-10 minute TEC variations\", clims=C_LIMITS)\n",
    "plot_line(1.500, datetime(2023, 2, 6, 1, 26, 0), style='dashed')\n",
    "plot_line(1.300, datetime(2023, 2, 6, 1, 28, 3))\n",
    "plot_line(0.900, datetime(2023, 2, 6, 1, 32), style='dotted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc44b76f",
   "metadata": {},
   "source": [
    "# Compare north-south effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e49f4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_LIMITS ={\n",
    "    'ROTI': [-0,0.5,'TECu/min\\n'],\n",
    "    '2-10 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    '10-20 minute TEC variations': [-0.4,0.4,'TECu'],\n",
    "    '20-60 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    'tec': [0,50,'TECu/min'],\n",
    "    'tec_adjusted': [0,50,'TECu'],\n",
    "}\n",
    "\n",
    "eq_location = EPICENTERS['10:24']\n",
    "\n",
    "#data = retrieve_data(\"dtec_2_10_10_24.h5\", \"2-10 minute TEC variations\")\n",
    "data = retrieve_data_multiple_source([\"dtec_2_10_10_24.h5\", \"tnpgn_dtec_2_10_10_24.h5\"], \n",
    "                                      \"2-10 minute TEC variations\")\n",
    "x, y, c = get_dist_time(data, eq_location, direction=\"north\")\n",
    "plot_distance_time(x, y, c, \"2-10 minute TEC variations\", clims=C_LIMITS)\n",
    "plot_line(1.500, datetime(2023, 2, 6, 10, 33), style='dashed')\n",
    "plot_line(1.400, datetime(2023, 2, 6, 10, 37, 30))\n",
    "plot_line(1.100, datetime(2023, 2, 6, 10, 42), style='dotted')\n",
    "\n",
    "x, y, c = get_dist_time(data, eq_location, direction=\"south\")\n",
    "plot_distance_time(x, y, c, \"2-10 minute TEC variations\", clims=C_LIMITS)\n",
    "plot_line(1.500, datetime(2023, 2, 6, 10, 32), style='dashed')\n",
    "plot_line(1.200, datetime(2023, 2, 6, 10, 34, 30))\n",
    "plot_line(0.900, datetime(2023, 2, 6, 10, 37), style='dotted')\n",
    "\n",
    "#data = retrieve_data(\"roti_10_24.h5\", \"ROTI\")\n",
    "data = retrieve_data_multiple_source([\"roti_10_24.h5\", \"tnpgn_roti_10_24.h5\"],\n",
    "                                      \"ROTI\")\n",
    "x, y, c = get_dist_time(data, eq_location, direction=\"north\")\n",
    "plot_distance_time(x, y, c, \"ROTI\", clims=C_LIMITS)\n",
    "plot_line(2.000, datetime(2023, 2, 6, 10, 35))\n",
    "\n",
    "x, y, c = get_dist_time(data, eq_location, direction=\"south\")\n",
    "plot_distance_time(x, y, c, \"ROTI\", clims=C_LIMITS, clims=C_LIMITS)\n",
    "plot_line(2.000, datetime(2023, 2, 6, 10, 35))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22891bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_LIMITS ={\n",
    "    'ROTI': [-0,0.6,'TECu/min\\n'],\n",
    "    '2-10 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    '10-20 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    '20-60 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    'tec': [0,50,'TECu/min'],\n",
    "    'tec_adjusted': [0,50,'TECu'],\n",
    "}\n",
    "\n",
    "eq_location = EPICENTERS['10:24']\n",
    "data = retrieve_data_multiple_source([\"dtec_10_20_10_24.h5\", \"tnpgn_dtec_10_20_10_24.h5\"], \n",
    "                                      \"10-20 minute TEC variations\")\n",
    "x, y, c = get_dist_time(data, eq_location, direction=\"north\")\n",
    "plot_distance_time(x, y, c, \"10-20 minute TEC variations\", clims=C_LIMITS)\n",
    "plot_line(1.500, datetime(2023, 2, 6, 10, 33), style='dashed')\n",
    "plot_line(1.400, datetime(2023, 2, 6, 10, 37, 30))\n",
    "plot_line(1.100, datetime(2023, 2, 6, 10, 42), style='dotted')\n",
    "\n",
    "x, y, c = get_dist_time(data, eq_location, direction=\"south\")\n",
    "plot_distance_time(x, y, c, \"10-20 minute TEC variations\", clims=C_LIMITS)\n",
    "plot_line(1.500, datetime(2023, 2, 6, 10, 32), style='dashed')\n",
    "plot_line(1.200, datetime(2023, 2, 6, 10, 34, 30))\n",
    "plot_line(0.900, datetime(2023, 2, 6, 10, 37), style='dotted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631eac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_LIMITS ={\n",
    "    'ROTI': [0, 0.15,'TECu/min\\n'],\n",
    "    '2-10 minute TEC variations': [-0.2,0.2,'TECu'],\n",
    "    '10-20 minute TEC variations': [-0.2,0.2,'TECu'],\n",
    "    '20-60 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    'tec': [0,50,'TECu/min'],\n",
    "    'tec_adjusted': [0,50,'TECu'],\n",
    "}\n",
    "eq_location = EPICENTERS['01:17']\n",
    "\n",
    "#data = retrieve_data(\"dtec_2_10_01_17.h5\", \"2-10 minute TEC variations\")\n",
    "data = retrieve_data_multiple_source([\"dtec_2_10_01_17.h5\", \"tnpgn_dtec_2_10_01_17.h5\"], \n",
    "                                      \"2-10 minute TEC variations\")\n",
    "\n",
    "times = [t for t in data]\n",
    "times.sort()\n",
    "data = {t: data[t] for t in times[120:]} # start from 01:00 UT\n",
    "x, y, c = get_dist_time(data, eq_location, direction=\"north\")\n",
    "plot_distance_time(x, y, c, \"2-10 minute TEC variations\", clims=C_LIMITS)\n",
    "plot_line(1.500, datetime(2023, 2, 6, 1, 26), style='dashed')\n",
    "plot_line(1.300, datetime(2023, 2, 6, 1, 29))\n",
    "plot_line(0.900, datetime(2023, 2, 6, 1, 32), style='dotted')\n",
    "\n",
    "x, y, c = get_dist_time(data, eq_location, direction=\"south\")\n",
    "plot_distance_time(x, y, c, \"2-10 minute TEC variations\", clims=C_LIMITS)\n",
    "plot_line(1.500, datetime(2023, 2, 6, 1, 25, 3), style='dashed')\n",
    "plot_line(1.300, datetime(2023, 2, 6, 1, 28, 30))\n",
    "plot_line(0.900, datetime(2023, 2, 6, 1, 31, 30), style='dotted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a537fa",
   "metadata": {},
   "source": [
    "# Ionosonde\n",
    "\n",
    "Here we plot foF2 and hmF2 data for earthquake day and day before and after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec11d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "from collections import defaultdict\n",
    "\n",
    "fmt = '%Y-%m-%dT%H:%M:%S.%fZ'\n",
    "convert = lambda x: datetime.strptime(x.decode(), fmt).timestamp()\n",
    "\n",
    "data = {}\n",
    "times = {}\n",
    "earthquake_times = defaultdict(dict)\n",
    "earthquake_data = defaultdict(dict)\n",
    "after_times = defaultdict(dict)\n",
    "before_times = defaultdict(dict)\n",
    "after_data = defaultdict(dict)\n",
    "before_data = defaultdict(dict)\n",
    "\n",
    "data['Nicosia (35.025N 33.157E)'] = np.loadtxt('./ionosonde/nicosia.dat', converters={0:convert})\n",
    "#data['jeju'] = np.loadtxt('./ionosonde/jeju.dat', converters={0:convert})\n",
    "#data['elarenosillo'] = np.loadtxt('./ionosonde/elarenosillo.dat', converters={0:convert})\n",
    "#data['eglin'] = np.loadtxt('./ionosonde/eglin.dat', converters={0:convert})\n",
    "\n",
    "\n",
    "    \n",
    "for station in data:\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(20, 8))\n",
    "    axs=axs.flatten()\n",
    "    for plot_ax, data_ind, data_label in zip(axs, (2, 4), ('foF2, MHz', 'hmF2, km')):\n",
    "        product = data_label.split(',')[0]\n",
    "        for station in data:\n",
    "            times[station] = [datetime.fromtimestamp(x[0]) for x in data[station]]\n",
    "            earthquake_times[product][station] = [t for t in times[station] if t.day == 6]\n",
    "            after_times[product][station] = [t.replace(day=6) for t in times[station] if t.day > 6]\n",
    "            before_times[product][station] = [t.replace(day=6) for t in times[station] if t.day < 6]\n",
    "            earthquake_data[product][station] = [data[station][i, data_ind] for i, t in enumerate(times[station]) if t.day == 6]\n",
    "            after_data[product][station] = [data[station][i, data_ind] for i, t in enumerate(times[station]) if t.day > 6]\n",
    "            before_data[product][station] = [data[station][i, data_ind] for i, t in enumerate(times[station]) if t.day < 6]\n",
    "        #plot_ax = plt.axes()\n",
    "        plot_ax.set_title(station)\n",
    "        plot_ax.scatter(before_times[product][station], \n",
    "                    before_data[product][station], \n",
    "                    label='Before earthquake')\n",
    "        plot_ax.scatter(after_times[product][station], \n",
    "                    after_data[product][station], \n",
    "                    label='After earthquake')\n",
    "        plot_ax.scatter(earthquake_times[product][station], \n",
    "                    earthquake_data[product][station], \n",
    "                    label='Earthquake day')\n",
    "\n",
    "        plot_ax.set_xlim(earthquake_times[product][station][0], earthquake_times[product][station][-1])\n",
    "        plot_ax.grid()\n",
    "        plot_ax.set_ylabel(data_label)\n",
    "        plot_ax.set_xlabel('UTC')\n",
    "        plot_ax.legend()\n",
    "        plot_ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M\"))\n",
    "        plot_ax.axvline(x=datetime(2023, 2, 6, 10, 24), color='red')\n",
    "        plot_ax.axvline(x=datetime(2023, 2, 6, 1, 17), color='red')\n",
    "        \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6a0d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "def spline_detrend(data, sm_f = 8):\n",
    "    \"\"\"\n",
    "    Takes data of raw TEC and return detrend TEC\n",
    "    Parameters\n",
    "    ----------\n",
    "    :param data: numpy array or list\n",
    "        Raw TEC,len of data must be more then 3\n",
    "    :param sm_f: int, sm_f\n",
    "        smoothing factor of spline\n",
    "    ----------\n",
    "    Returns numpy array: TEC without trend\n",
    "    \"\"\"\n",
    "    if len(data) > 3:\n",
    "        x = np.arange(len(data))\n",
    "        spl = UnivariateSpline(x, data)\n",
    "        spl.set_smoothing_factor(sm_f)\n",
    "        dif_spl = np.zeros(len(data))\n",
    "        trend = np.zeros(len(data))\n",
    "        for j in range(len(data)):\n",
    "            dif_spl[j] = data[j] - spl(x[j])\n",
    "            trend[j] = spl(x[j])\n",
    "        return dif_spl, trend\n",
    "    else:\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77ec309",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(15, 10))\n",
    "for plot_ax, product in zip(axs, ('foF2', 'hmF2')):\n",
    "    _product_data = earthquake_data[product]['Nicosia (35.025N 33.157E)'][:]\n",
    "    product_data = earthquake_data[product]['Nicosia (35.025N 33.157E)'][:]\n",
    "    for _ in range(1):\n",
    "        for i in range(1, len(product_data)-1):\n",
    "            ratio = product_data[i] / ((product_data[i-1] + product_data[i+1]) / 2)\n",
    "            if not (0.8 < ratio < 1.2) and abs(1 - product_data[i-1] / product_data[i+1]) < 0.2:\n",
    "\n",
    "                product_data[i] = (product_data[i-1] + product_data[i+1]) / 2\n",
    "                \n",
    "    detrended, trend = spline_detrend(product_data,\n",
    "                                      sm_f = 12)\n",
    "    #plot_ax.plot(earthquake_times[product][station], product_data, label=product)\n",
    "    #plot_ax.plot(earthquake_times[product][station], _product_data, label=product)\n",
    "    plot_ax.plot(earthquake_times[product][station], detrended, label=product)\n",
    "    #plot_ax.plot(earthquake_times[product][station], trend, label=product)\n",
    "    \n",
    "    plot_ax.set_xlim(earthquake_times[product][station][0], earthquake_times[product][station][-1])\n",
    "    plot_ax.grid()\n",
    "    plot_ax.set_ylabel(product)\n",
    "    plot_ax.set_xlabel('UTC')\n",
    "    plot_ax.legend()\n",
    "    plot_ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M\"))\n",
    "    plot_ax.axvline(x=datetime(2023, 2, 6, 10, 24), color='red')\n",
    "    plot_ax.axvline(x=datetime(2023, 2, 6, 1, 17), color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fea256",
   "metadata": {},
   "source": [
    "# TNPGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c01e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_LIMITS ={\n",
    "    'ROTI': [-0,0.5,'TECu/min\\n'],\n",
    "    '2-10 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    '10-20 minute TEC variations': [-0.8,0.8,'TECu'],\n",
    "    '20-60 minute TEC variations': [-1.0,1.0,'TECu'],\n",
    "    'tec': [0,50,'TECu/min'],\n",
    "    'tec_adjusted': [0,50,'TECu'],\n",
    "}\n",
    "\n",
    "eq_location = EPICENTERS['10:24']\n",
    "\n",
    "data = retrieve_data(\"tnpgn_roti_10_24.h5\", \"ROTI\")\n",
    "x, y, c = get_dist_time(data, eq_location)\n",
    "plot_distance_time(x, y, c, \"ROTI\")\n",
    "plot_line(2.000, datetime(2023, 2, 6, 10, 35))\n",
    "\n",
    "data = retrieve_data(\"tnpgn_dtec_2_10_10_24.h5\", \"2-10 minute TEC variations\")\n",
    "x, y, c = get_dist_time(data, eq_location)\n",
    "plot_distance_time(x, y, c, \"2-10 minute TEC variations\")\n",
    "plot_line(1.500, datetime(2023, 2, 6, 10, 32), style='dashed')\n",
    "plot_line(1.300, datetime(2023, 2, 6, 10, 34, 30))\n",
    "plot_line(0.900, datetime(2023, 2, 6, 10, 37), style='dotted')\n",
    "\n",
    "data = retrieve_data(\"tnpgn_dtec_10_20_10_24.h5\", \"10-20 minute TEC variations\")\n",
    "x, y, c = get_dist_time(data, eq_location)\n",
    "plot_distance_time(x, y, c, \"10-20 minute TEC variations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c105cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_LIMITS ={\n",
    "    'ROTI': [-0,0.5,'TECu/min\\n'],\n",
    "    '2-10 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    '10-20 minute TEC variations': [-0.8,0.8,'TECu'],\n",
    "    '20-60 minute TEC variations': [-1.0,1.0,'TECu'],\n",
    "    'tec': [0,50,'TECu/min'],\n",
    "    'tec_adjusted': [0,50,'TECu'],\n",
    "}\n",
    "\n",
    "eq_location = EPICENTERS['10:24']\n",
    "\n",
    "data = retrieve_data(\"tnpgn_dtec_2_10_10_24.h5\", \"2-10 minute TEC variations\")\n",
    "x, y, c = get_dist_time(data, eq_location)\n",
    "plot_distance_time(x, y, c, \"2-10 minute TEC variations\")\n",
    "plot_line(1.500, datetime(2023, 2, 6, 10, 32), style='dashed')\n",
    "plot_line(1.300, datetime(2023, 2, 6, 10, 34, 30))\n",
    "plot_line(0.900, datetime(2023, 2, 6, 10, 37), style='dotted')\n",
    "\n",
    "C_LIMITS ={\n",
    "    'ROTI': [0, 0.15,'TECu/min\\n'],\n",
    "    '2-10 minute TEC variations': [-0.2,0.2,'TECu'],\n",
    "    '10-20 minute TEC variations': [-0.2,0.2,'TECu'],\n",
    "    '20-60 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    'tec': [0,50,'TECu/min'],\n",
    "    'tec_adjusted': [0,50,'TECu'],\n",
    "}\n",
    "\n",
    "eq_location = EPICENTERS['01:17']\n",
    "\n",
    "data = retrieve_data(\"tnpgn_dtec_2_10_01_17.h5\", \"2-10 minute TEC variations\")\n",
    "times = [t for t in data]\n",
    "times.sort()\n",
    "#data = {t: data[t] for t in times[120:]} # start from 01:00 UT\n",
    "x, y, c = get_dist_time(data, eq_location)\n",
    "plot_distance_time(x, y, c, \"2-10 minute TEC variations\")\n",
    "plot_line(1.500, datetime(2023, 2, 6, 1, 26), style='dashed')\n",
    "plot_line(1.300, datetime(2023, 2, 6, 1, 29))\n",
    "plot_line(0.900, datetime(2023, 2, 6, 1, 32), style='dotted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b46ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_LIMITS ={\n",
    "    'ROTI': [-0,0.5,'TECu/min\\n'],\n",
    "    '2-10 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    '10-20 minute TEC variations': [-0.4,0.4,'TECu'],\n",
    "    '20-60 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    'tec': [0,50,'TECu/min'],\n",
    "    'tec_adjusted': [0,50,'TECu'],\n",
    "}\n",
    "\n",
    "eq_location = EPICENTERS['10:24']\n",
    "\n",
    "data = retrieve_data(\"tnpgn_roti_10_24.h5\", \"ROTI\")\n",
    "x, y, c = get_dist_time(data, eq_location)\n",
    "plot_distance_time(x, y, c, \"ROTI\")\n",
    "\n",
    "C_LIMITS ={\n",
    "    'ROTI': [0, 0.3,'TECu/min\\n'],\n",
    "    '2-10 minute TEC variations': [-0.4,0.4,'TECu'],\n",
    "    '10-20 minute TEC variations': [-0.4,0.4,'TECu'],\n",
    "    '20-60 minute TEC variations': [-0.6,0.6,'TECu'],\n",
    "    'tec': [0,50,'TECu/min'],\n",
    "    'tec_adjusted': [0,50,'TECu'],\n",
    "}\n",
    "\n",
    "eq_location = EPICENTERS['01:17']\n",
    "\n",
    "data = retrieve_data(\"tnpgn_roti_01_17.h5\", \"ROTI\")\n",
    "times = [t for t in data]\n",
    "times.sort()\n",
    "x, y, c = get_dist_time(data, eq_location)\n",
    "plot_distance_time(x, y, c, \"ROTI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f9bceb",
   "metadata": {},
   "source": [
    "# Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250beb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PPP_STRUCTURE = \"Year,Month,Day,HH,MM,SS,GPSweek,timestamp,\"\\\n",
    "                \"X,Y,Z,Xerror,Yerror,Zerror,3Derror,lat,lon,alt,d_alt\"\n",
    "PPP_FIELDS = PPP_STRUCTURE.split(\",\")\n",
    "PPP_ROOT = \"./coords\"\n",
    "PPP_FIELDS_INDS = {f: i for i, f in enumerate(PPP_FIELDS)}\n",
    "\n",
    "def get_filenames(root_path, select='by_time'):\n",
    "    files = list()\n",
    "    for f in os.listdir(root_path):\n",
    "        if select == 'by_time':\n",
    "            if f.lower().startswith('GPS_Errors_2023'.lower()):\n",
    "                files.append(Path(root_path) / f)\n",
    "        elif select == 'by_site':\n",
    "            if not f.lower().startswith('GPS_Errors_2023'.lower()):\n",
    "                files.append(Path(root_path) / f)\n",
    "        else:\n",
    "            raise ValueError('Unknown selection type, use [by_time | by_site]')\n",
    "    return files\n",
    "            \n",
    "        \n",
    "def get_coord_data(pth):\n",
    "    sites = list()\n",
    "    with open(pth) as f:\n",
    "        skip_lines=1\n",
    "        for line in f:\n",
    "            if skip_lines:\n",
    "                skip_lines = skip_lines - 1 \n",
    "                continue\n",
    "            site = line.split(',')[16]\n",
    "            sites.append(site)\n",
    "    cols = [i for i in range(1,16)] + [i for i in range(17, 21)]\n",
    "    ppp_data = np.loadtxt(pth, skiprows=1, delimiter=\",\", usecols=cols)\n",
    "    if len(ppp_data) != len(sites):\n",
    "        raise ValueError(f'Check data ({len(ppp_data)}) and sites ({len(sites)}) length')\n",
    "    times = list()\n",
    "    for d in ppp_data:\n",
    "        tokens = [int(t) for t in d[0:6]]\n",
    "        times.append(datetime(*tokens))\n",
    "    return sites, times, ppp_data\n",
    "\n",
    "def convert_files_to_data(files, val_field='Zerror', start=None, fin=None):\n",
    "    map_data = dict()\n",
    "    for file in files:\n",
    "        sites, times, data = get_coord_data(file)\n",
    "        if not len(set(times)) == 1:\n",
    "            raise ValueError(f'Multiple times {(set(times))} in {file}')\n",
    "        _time = list(set(times))[0]\n",
    "        if not start <= _time <= fin:\n",
    "            continue\n",
    "        map_data[_time] = {'lat': data[:, PPP_FIELDS_INDS['lat']], \n",
    "                           'lon': data[:, PPP_FIELDS_INDS['lon']], \n",
    "                           'vals': data[:, PPP_FIELDS_INDS[val_field]], \n",
    "                      }\n",
    "    return map_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929c9c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_filenames(PPP_ROOT, select='by_time')\n",
    "for product in ['Xerror', 'Yerror', 'Zerror']:\n",
    "    data = convert_files_to_data(files, \n",
    "                                 val_field=product,\n",
    "                                 start=datetime(2023, 2, 6, 1),\n",
    "                                 fin=datetime(2023, 2, 6, 2))\n",
    "    eq_location = EPICENTERS['01:17']\n",
    "    x, y, c = get_dist_time(data, eq_location)\n",
    "    plot_distance_time(x, y, c, \"PPP error\", clims={\"PPP error\": [-0.1, 0.1, product + \", m\"]}, dmax=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94f56a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_filenames(PPP_ROOT, select='by_time')\n",
    "for product in ['Xerror', 'Yerror', 'Zerror']:\n",
    "    data = convert_files_to_data(files, \n",
    "                                 val_field=product,\n",
    "                                 start=datetime(2023, 2, 6, 10),\n",
    "                                 fin=datetime(2023, 2, 6, 11))\n",
    "    eq_location = EPICENTERS['10:24']\n",
    "    x, y, c = get_dist_time(data, eq_location)\n",
    "    plot_distance_time(x, y, c, \"PPP error\", clims={\"PPP error\": [-0.1, 0.1, product + \", m\"]}, dmax=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3a3ffc",
   "metadata": {},
   "source": [
    "# Support code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d41c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_sats(local_file, site, product, shift=0.5):\n",
    "    f = h5py.File(local_file)\n",
    "    plt.figure(figsize=(10, 13))\n",
    "    plot_ax = plt.axes()\n",
    "    i = 0\n",
    "    locs = list()\n",
    "    label_sats = list()\n",
    "    print(site, np.degrees(f[site].attrs['lat']), np.degrees(f[site].attrs['lon']) )\n",
    "    for sat in f[site]:\n",
    "        tstamps = f[site][sat]['timestamp'][:]\n",
    "        times = [datetime.utcfromtimestamp(t) for t in tstamps]\n",
    "        i = i + shift\n",
    "        plt.scatter(times, f[site][sat][product][:] + i, label=sat)\n",
    "        locs.append(i)\n",
    "        label_sats.append(sat)\n",
    "    plt.yticks(locs, label_sats)\n",
    "    plt.xlim(datetime(2023, 2, 6), datetime(2023, 2, 7))\n",
    "    #plt.ylim(0, 3.1415 * 0.5)\n",
    "    plt.grid()\n",
    "    plot_ax.axvline(x=datetime(2023, 2, 6, 10, 24), color='red')\n",
    "    plot_ax.axvline(x=datetime(2023, 2, 6, 1, 17), color='red')\n",
    "    plot_ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M\"))\n",
    "    \n",
    "def plot_sites(local_file, plot_sat, sites, product, shift=0.5):\n",
    "    f = h5py.File(local_file)\n",
    "    plt.figure(figsize=(10, 13))\n",
    "    plot_ax = plt.axes()\n",
    "    i = 0\n",
    "    locs = list()\n",
    "    label_sats = list()\n",
    "    for site in f:\n",
    "        if not site in sites:\n",
    "            continue\n",
    "        print(site, np.degrees(f[site].attrs['lat']), np.degrees(f[site].attrs['lon']) )\n",
    "        for sat in f[site]:\n",
    "            if not sat == plot_sat:\n",
    "                continue\n",
    "            tstamps = f[site][sat]['timestamp'][:]\n",
    "            times = [datetime.utcfromtimestamp(t) for t in tstamps]\n",
    "            i = i + shift\n",
    "            plt.scatter(times, f[site][sat][product][:] + i, label=sat)\n",
    "            locs.append(i)\n",
    "            label_sats.append(site)\n",
    "    plt.yticks(locs, label_sats)\n",
    "    plt.xlim(datetime(2023, 2, 6, 10), datetime(2023, 2, 6, 11))\n",
    "    #plt.ylim(0, 3.1415 * 0.5)\n",
    "    plt.grid()\n",
    "    plot_ax.axvline(x=datetime(2023, 2, 6, 10, 24), color='red')\n",
    "    plot_ax.axvline(x=datetime(2023, 2, 6, 1, 17), color='red')\n",
    "    plot_ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9f6c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['mers', 'nico', 'bshm', 'csar', 'mrav', 'nzrt', 'hama', \n",
    "         'hrmn', 'drag', 'kabr', 'katz', 'zkro', 'tmar', 'ista']\n",
    "local_file = 'region_2023-02-06.h5'\n",
    "sat = 'G17'\n",
    "plot_sites(local_file, sat, sites, 'roti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e67ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['mers', 'nico', 'bshm', 'csar', 'mrav', 'nzrt', 'hama', \n",
    "         'hrmn', 'drag', 'kabr', 'katz', 'zkro', 'tmar', 'ista']\n",
    "local_file = 'region_self_processed_2023-02-06.h5'\n",
    "sat = 'G17'\n",
    "plot_sites(local_file, sat, sites, 'roti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db481e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['anmu', 'fini', 'mrsi', 'silf', 'kamn', 'sarv', 'aksi', \n",
    "         'alny', 'lefk', 'mgos', 'bcak', 'antl', 'cav2', 'elmi', \n",
    "         'kaas', 'feth', 'mug1', 'slee', 'istn', 'karb', 'ylov', \n",
    "         'boyt', 'sary', 'slvr', 'vezi', 'tekr', 'kstm', 'cank', \n",
    "         'kuru', 'cmld', 'zong']\n",
    "local_file = 'tnpgn_2023-02-06.h5'\n",
    "sat = 'G17'\n",
    "plot_sites(local_file, sat, sites[:], 'roti')\n",
    "#plot_sites(local_file, sat, sites[:15], 'roti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd39cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "site = '23ey'\n",
    "local_file = 'region_2023-02-06.h5'\n",
    "plot_all_sats(local_file, site, 'roti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24a5caf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
